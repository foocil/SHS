{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import bz2\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "from bz2 import BZ2File\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to data, json and our corpus\n",
    "pathToData = \"data/\"\n",
    "pathToJson = \"jsonl_created/\" \n",
    "pathToBz2 = \"ourCorpusBZ2/\"\n",
    "files_to_read = os.listdir(pathToData) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function to get the JSON lines from an archive \n",
    "def read_jsonlines(bz2_file):\n",
    "    text = bz2_file.read().decode('utf-8')\n",
    "    for line in text.split('\\n'):\n",
    "        if line != '':\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function clean the whole corpus into a smaller corpus with the list of our words (not case sensitive)\n",
    "#It creates another corpus of the format bz2 and it keeps the json format.\n",
    "def createOurCorpus():\n",
    "    nb =1\n",
    "    count =0\n",
    "    returntxt = open(\"txtname.txt\", \"w+\")\n",
    "    for file in files_to_read:\n",
    "        filename = file[0:14]\n",
    "        with open(\"jsonl_created/\"+filename, 'w') as outfile:  \n",
    "            text_article = \"\"\n",
    "            #open the file \n",
    "            f = BZ2File(os.path.join(pathToData, file), 'r')\n",
    "            # get the list of articles it contains (= a json object on each line)\n",
    "            articles = list(read_jsonlines(f))\n",
    "            # load the first 100 articles as json and access their attributes\n",
    "            for a in articles:\n",
    "                # decode the json string into an object (dict)\n",
    "                json_article = json.loads(a)\n",
    "                jsonString = {}\n",
    "                ### Change here the keyword to search for\n",
    "                if \"apartheid\" or \"afrique du sud\" or \"sharpeville\" or \"ssca\" or \"anc\" or \"sarb\" or \"soweto\" or \"mandela\" or \"pretoria\" or \"johannesburg\" or \"bloemfontein\" or \"le cap\" in json_article[\"ft\"].lower(): ### expression régulière pour checker ca\n",
    "                    text_article = text_article + \" \\n**** *id:\" + str(count) + \" *from:\" + file + \"  \\n \" + json_article[\"ft\"]\n",
    "                    jsonString = {'id' : str(count), 'd' : json_article[\"d\"], 'ft' : json_article[\"ft\"], 'pp' : json_article[\"pp\"]}\n",
    "                    json.dump(jsonString, outfile)\n",
    "                    outfile.write('\\n')\n",
    "                    count += 1\n",
    "            returntxt.write(text_article)\n",
    "            nb = nb + 1 \n",
    "        f = bz2.compress(open(pathToJson + filename, 'rb').read())\n",
    "        fh = open(pathToBz2 + filename + \"A.bz2\", 'wb')\n",
    "        fh.write(f)\n",
    "        fh.close()\n",
    "    returntxt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createOurCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the path to our corpus\n",
    "files_to_read = os.listdir(pathToBz2)\n",
    "files_to_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function clean our corpus into a smaller corpus with the word apartheid (not case sensitive)\n",
    "#It creates another corpus of the format bz2 and it keeps the json format.\n",
    "def createCorpusApartheid():\n",
    "    #From the big corpus to our corpus in json.bz2\n",
    "    nb =1\n",
    "    count =0\n",
    "    returntxt = open(\"Apartheid/txtname.txt\", \"w+\")\n",
    "    for file in files_to_read:\n",
    "        filename = file[0:14]\n",
    "        with open(\"Apartheid/json/\"+filename, 'w') as outfile:  \n",
    "            text_article = \"\"\n",
    "            #open the file \n",
    "            f = BZ2File(os.path.join(pathToBz2, file), 'r')\n",
    "            # get the list of articles it contains (= a json object on each line)\n",
    "            articles = list(read_jsonlines(f))\n",
    "            # load the first 100 articles as json and access their attributes\n",
    "            for a in articles:\n",
    "                # decode the json string into an object (dict)\n",
    "                json_article = json.loads(a)\n",
    "                jsonString = {}\n",
    "                ### Change here the keyword to search for (can add more than one connected with AND / OR)\n",
    "                if \"apartheid\" in json_article[\"ft\"].lower(): \n",
    "                    text_article = text_article + \" \\n**** *id:\" + str(count) + \" *from:\" + file + \"  \\n \" + json_article[\"ft\"]\n",
    "                    jsonString = {'id' : str(count), 'd' : json_article[\"d\"], 'ft' : json_article[\"ft\"], 'pp' : json_article[\"pp\"]}\n",
    "                    json.dump(jsonString, outfile)\n",
    "                    outfile.write('\\n')\n",
    "                    count += 1\n",
    "            returntxt.write(text_article)\n",
    "            nb = nb + 1 \n",
    "        f = bz2.compress(open(\"Apartheid/json/\" + filename, 'rb').read())\n",
    "        fh = open(\"Apartheid/bz2/\" + filename + \"A.bz2\", 'wb')\n",
    "        fh.write(f)\n",
    "        fh.close()\n",
    "    returntxt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createCorpusApartheid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_read = os.listdir(\"Apartheid/bz2/\")\n",
    "files_to_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function selects the date in our corpus that are between the 2 delta date. \n",
    "# y: year, m: month, d: day of the event deltap: the delta from date of the event to max in days, deltan: the delta to date of the event from min in days\n",
    "def csvtxtwriter(csvname, y, m, d, deltap, deltan):\n",
    "    nb =0\n",
    "    count =0\n",
    "    dateMax = datetime.timedelta(days = deltap)\n",
    "    dateMin = datetime.timedelta(days = deltan)\n",
    "    dateEventstring = str(y)+\"-\"+str(m) + \"-\"+str(d)\n",
    "    dateEvent = datetime.datetime.strptime(dateEventstring, '%Y-%m-%d')\n",
    "    #path to the csv, if \"Apartheid\" then we look at the small corpus with only the word apartheid\n",
    "    pathCSV = \"Apartheid/csv/\"\n",
    "    text_articletxt = \"\"\n",
    "    #open the csv to write inside\n",
    "    with open(pathCSV + csvname, 'w', newline='') as csvFinal:\n",
    "        linewriter = csv.writer(csvFinal, delimiter = '*')\n",
    "        linewriter.writerow([\"id\", \"date\"])\n",
    "        for file in files_to_read:\n",
    "            nb +=1\n",
    "            #open the file \n",
    "            f = BZ2File(os.path.join(\"Apartheid/bz2/\", file), 'r') #if the path doesnt have the Apartheid/ it looks at our corpus with a list of words\n",
    "            # get the list of articles it contains (= a json object on each line)\n",
    "            articles = list(read_jsonlines(f))\n",
    "            # load the first 100 articles as json and access their attributes\n",
    "            for a in articles:\n",
    "                # decode the json string into an object (dict)\n",
    "                json_article = json.loads(a)\n",
    "                datearticle = datetime.datetime.strptime(json_article[\"d\"], '%Y-%m-%d')\n",
    "                if ((datearticle - dateEvent < dateMax) and (datearticle - dateEvent > dateMin)) :\n",
    "                    #write the date\n",
    "                    linewriter.writerow([str(count), json_article[\"d\"][:7]]) ###if we want a groupbyday: remove \"[:7]\"\n",
    "                    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The date we want: year / month / day \n",
    "datey = [1948, 1960, 1976, 1983, 1986, 1990, 1990, 1962, 1949]\n",
    "datem = [6, 3, 6, 5, 6, 3, 2, 8, 6]\n",
    "dated = [15, 21, 16, 20, 12, 15, 11, 15, 29]\n",
    "title = [\"début de l'Apartheid\", \"Massacre de Sharpeville\", \"Émeutes de Soweto\", \"Attentat de Church Street\", \"état d'urgence\", \"légalisation des partis politiques\", \"libération de Mandela\", \"Condamnation de Mandela\", \"test1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate every csv from the lists above with the different dates\n",
    "for d in range(0, len(datey)-1):\n",
    "    print(\"FOR TOTAL: \" + str(d) + \"/\" + str(len(datey)))\n",
    "    name = str(datey[d]) +\"_\" + str(datem[d]) + \".csv\"\n",
    "    csvtxtwriter(name, datey[d], datem[d], dated[d], 366, -366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a graph from the csv files to see the occurences. We use a groupby on date with year and month only\n",
    "def fromCSVtoGraph(csvname, title):\n",
    "    a = pd.read_csv(csvname, delimiter='*')\n",
    "    futurG = a.groupby(['date']).count().sort_values(by='date')\n",
    "    ax = futurG.plot(kind='bar', title = title)\n",
    "    middle = len(ax.get_xticklabels()[:]) / 2\n",
    "    ax.get_xticklabels()[int(middle)].set_color(\"red\")\n",
    "    ax.legend([\"Occurences\"]);\n",
    "    plt.savefig(\"Apartheid/fig/\"+title+\".pdf\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to_read = os.listdir(\"Apartheid/csv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the graph from the csv for all dates\n",
    "indexi = 0\n",
    "for csv in csv_to_read:\n",
    "    fromCSVtoGraph(\"Apartheid/csv/\" + csv, title[indexi])\n",
    "    indexi = indexi + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
