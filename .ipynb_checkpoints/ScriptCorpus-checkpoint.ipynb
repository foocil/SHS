{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import bz2\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "from bz2 import BZ2File\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToData = \"data/\"\n",
    "pathToJson = \"jsonl_created/\" \n",
    "pathToBz2 = \"ourCorpusBZ2/\"\n",
    "pathToBz2A = \"bz2Apartheid/\"\n",
    "pathToJsonA = \"json_apartheid/\"\n",
    "files_to_read = os.listdir(pathToData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonlines(bz2_file):\n",
    "    # a helper function to get the lines from am archive\n",
    "    text = bz2_file.read().decode('utf-8')\n",
    "    for line in text.split('\\n'):\n",
    "        if line != '':\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOurCorpus():\n",
    "    #From the big corpus json-bz2 to our corpus in json.bz2: keeps all articles which contain at least one word of the listword\n",
    "    nb =1\n",
    "    count =0\n",
    "    returntxt = open(\"txtname.txt\", \"w+\")\n",
    "    listword ='apartheid','afrique du sud','sharpeville',\"congrès nation africain\", \"congres national africain\", \"soweto\",\"mandela\",\"pretoria\",\"johannesburg\",\"bloemfontein\" \n",
    "\n",
    "    for file in files_to_read:\n",
    "        filename = file[0:14]\n",
    "        with open(pathToJson+filename, 'w') as outfile:  \n",
    "\n",
    "            print(file)\n",
    "            print(\" \" + str(nb) + \"/\"+ str(len(files_to_read)))\n",
    "            text_article = \"\"\n",
    "            #open the file \n",
    "            f = BZ2File(os.path.join(pathToData, file), 'r')\n",
    "            # get the list of articles it contains (= a json object on each line)\n",
    "            articles = list(read_jsonlines(f))\n",
    "            # load the first 100 articles as json and access their attributes\n",
    "            for a in articles:\n",
    "                # decode the json string into an object (dict)\n",
    "                json_article = json.loads(a)\n",
    "                jsonString = {}\n",
    "\n",
    "                ### Change here the keyword to search for (can add more than one connected with AND / OR)\n",
    "                if any(i in json_article[\"ft\"].lower() for i in listword): \n",
    "                    text_article = text_article + \" \\n**** *id:\" + str(count) + \" *from:\" + file + \"  \\n \" + json_article[\"ft\"]\n",
    "                    jsonString = {'id' : str(count), 'd' : json_article[\"d\"], 'ft' : json_article[\"ft\"], 'pp' : json_article[\"pp\"]}\n",
    "                    json.dump(jsonString, outfile)\n",
    "                    outfile.write('\\n')\n",
    "                    count += 1\n",
    "            returntxt.write(text_article)\n",
    "            nb = nb + 1 \n",
    "        f = bz2.compress(open(pathToJson + filename, 'rb').read())\n",
    "        fh = open(pathToBz2 + filename + \".bz2\", 'wb')\n",
    "        fh.write(f)\n",
    "        fh.close()\n",
    "    returntxt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "createOurCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_read = os.listdir(pathToBz2)\n",
    "files_to_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvtxtwriter(csvname, y, m, d, deltap, deltan):\n",
    "    ### y: year, m: month, d: day, deltap: the delta from dateEvent to max in days, deltan: the delta to dateEvent from min in days\n",
    "    ### dateEventstring: date of the event we want to look at.\n",
    "    ### create a CSV with all articles within a deltatime after and before a date, from the corpus json.bz2\n",
    "    ### it keeps the date, the apparition page, the length of the articles. Writes also 1 at the end of the line for the groupby\n",
    "    nb =0\n",
    "    count =0\n",
    "    dateMax = datetime.timedelta(days = deltap)\n",
    "    dateMin = datetime.timedelta(days = deltan)\n",
    "    dateEventstring = str(y)+\"-\"+str(m) + \"-\"+str(d)\n",
    "    dateEvent = datetime.datetime.strptime(dateEventstring, '%Y-%m-%d')\n",
    "    pathCSV = \"csv/\"\n",
    "    text_articletxt = \"\"\n",
    "    returntxt = open(csvname[0:5] + \".txt\", \"w+\")\n",
    "    with open(pathCSV + csvname, 'w+', newline='') as csvFinal:\n",
    "        linewriter = csv.writer(csvFinal, delimiter = '*')\n",
    "        linewriter.writerow([\"date\", \"pp\", \"lenstring\", \"frequency\"])\n",
    "        for file in files_to_read:\n",
    "            nb +=1\n",
    "            #open the file \n",
    "            f = BZ2File(os.path.join(pathToBz2, file), 'r')\n",
    "            # get the list of articles it contains (= a json object on each line)\n",
    "            articles = list(read_jsonlines(f))\n",
    "            # load the first 100 articles as json and access their attributes\n",
    "\n",
    "            for a in articles:\n",
    "                # decode the json string into an object (dict)\n",
    "                json_article = json.loads(a)\n",
    "                datearticle = datetime.datetime.strptime(json_article[\"d\"], '%Y-%m-%d')\n",
    "                if ((datearticle - dateEvent < dateMax) and (datearticle - dateEvent > dateMin)) :\n",
    "                    text_articletxt = text_articletxt + \" \\n**** *id:\" + str(count) + \" *from:\" + file + \"  \\n \" + json_article[\"ft\"]\n",
    "\n",
    "                    linewriter.writerow([str(json_article[\"d\"][:7]), json_article['pp'][0], len(json_article['ft']), int(1)]) ###if we want groupbyday: remove [:7]\n",
    "                    count += 1\n",
    "    returntxt.write(text_articletxt)\n",
    "    returntxt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apartheidCSV():\n",
    "    ### create a CSV with the word apartheid for the whole period.\n",
    "    with open(\"csv/apartheid.csv\", 'w+', newline='') as csvFinal:\n",
    "        linewriter = csv.writer(csvFinal, delimiter = '*')\n",
    "        linewriter.writerow([\"date\", \"pp\", \"lenstring\", \"frequency\"])\n",
    "        for file in files_to_read:\n",
    "            f = BZ2File(os.path.join(pathToBz2, file), 'r')\n",
    "            articles = list(read_jsonlines(f))\n",
    "            for a in articles:\n",
    "                json_article = json.loads(a)\n",
    "                linewriter.writerow([str(json_article['d'][:4]), json_article['pp'][0], len(json_article['ft']), int(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datey = [1948, 1960, 1976, 1983, 1986, 1990, 1990, 1962, 1949]\n",
    "datem = [6, 3, 6, 5, 6, 3, 2, 8, 6]\n",
    "dated = [15, 21, 16, 20, 12, 15, 11, 15, 29]\n",
    "title = [\"début de l'Apartheid\", \"Massacre de Sharpeville\", \"Émeutes de Soweto\", \"Attentat de Church Street\", \"état d'urgence\", \"légalisation des partis politiques\", \"libération de Mandela\", \"Condamnation de Mandela\", \"test1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupbycsvme(csvname):\n",
    "    ### redefine the groupby \n",
    "    a = pd.read_csv(\"csv/\"+csvname, delimiter='*')\n",
    "    futurG = a.groupby(['date']).sum().sort_values(by='date').reset_index()\n",
    "    with open(\"csvGrouped/\" + csvname, 'w+', newline='') as csvFinal:\n",
    "        linewriter = csv.writer(csvFinal, delimiter = '*')\n",
    "        linewriter.writerow([\"date\", \"pp\", \"lenstring\", \"frequency\"])\n",
    "        for i in range(0,len(futurG)):\n",
    "            linewriter.writerow([futurG['date'].iloc[i], futurG['pp'].iloc[i], futurG['lenstring'].iloc[i], futurG['frequency'].iloc[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apartheidCSV()\n",
    "for d in range(0, len(datey)-1):\n",
    "    print(str(d+1) + \"/\"+str(len(datey)-1))\n",
    "    name = str(datey[d]) +\"_\" + str(datem[d]) + \".csv\"\n",
    "    csvtxtwriter(name, datey[d], datem[d], dated[d], 388, -388)\n",
    "    groupbycsvme(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = str(datey[1]) +\"_\" + str(datem[1]) + \".csv\"\n",
    "###we created a csv with one more if: if a word was in the article only, we wrote it in the csv. Not updated anymore. \n",
    "csvtxtwriter(name, datey[1], datem[1], dated[1], 388, -388, \"sharpeville\")\n",
    "groupbycsvme(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
