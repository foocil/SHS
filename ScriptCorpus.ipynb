{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import bz2\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "from bz2 import BZ2File\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToData = \"data/\"\n",
    "pathToJson = \"jsonl_created/\" \n",
    "pathToBz2 = \"ourCorpusBZ2/\"\n",
    "pathToBz2A = \"bz2Apartheid/\"\n",
    "pathToJsonA = \"json_apartheid/\"\n",
    "files_to_read = os.listdir(pathToData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function to get the lines from am archive\n",
    "def read_jsonlines(bz2_file):\n",
    "    text = bz2_file.read().decode('utf-8')\n",
    "    for line in text.split('\\n'):\n",
    "        if line != '':\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOurCorpus():\n",
    "    #From the big corpus to our corpus in json.bz2\n",
    "    nb =1\n",
    "    count =0\n",
    "    returntxt = open(\"txtname.txt\", \"w+\")\n",
    "    listword ='apartheid','afrique du sud','sharpeville',\"congr√®s nation africain\", \"congres national africain\", \"soweto\",\"mandela\",\"pretoria\",\"johannesburg\",\"bloemfontein\" \n",
    "\n",
    "    for file in files_to_read:\n",
    "        filename = file[0:14]\n",
    "        with open(pathToJson+filename, 'w') as outfile:  \n",
    "\n",
    "            print(file)\n",
    "            print(\" \" + str(nb) + \"/\"+ str(len(files_to_read)))\n",
    "            text_article = \"\"\n",
    "            #open the file \n",
    "            f = BZ2File(os.path.join(pathToData, file), 'r')\n",
    "            # get the list of articles it contains (= a json object on each line)\n",
    "            articles = list(read_jsonlines(f))\n",
    "            # load the first 100 articles as json and access their attributes\n",
    "            for a in articles:\n",
    "                # decode the json string into an object (dict)\n",
    "                json_article = json.loads(a)\n",
    "                jsonString = {}\n",
    "\n",
    "                ### Change here the keyword to search for (can add more than one connected with AND / OR)\n",
    "                if any(i in json_article[\"ft\"].lower() for i in listword): \n",
    "                    text_article = text_article + \" \\n**** *id:\" + str(count) + \" *from:\" + file + \"  \\n \" + json_article[\"ft\"]\n",
    "                    jsonString = {'id' : str(count), 'd' : json_article[\"d\"], 'ft' : json_article[\"ft\"], 'pp' : json_article[\"pp\"]}\n",
    "                    json.dump(jsonString, outfile)\n",
    "                    outfile.write('\\n')\n",
    "                    count += 1\n",
    "            returntxt.write(text_article)\n",
    "            nb = nb + 1 \n",
    "        f = bz2.compress(open(pathToJson + filename, 'rb').read())\n",
    "        fh = open(pathToBz2 + filename + \".bz2\", 'wb')\n",
    "        fh.write(f)\n",
    "        fh.close()\n",
    "    returntxt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDL-1948.jsonl.bz2\n",
      " 1/88\n",
      "GDL-1949.jsonl.bz2\n",
      " 2/88\n",
      "GDL-1950.jsonl.bz2\n",
      " 3/88\n",
      "GDL-1951.jsonl.bz2\n",
      " 4/88\n",
      "GDL-1952.jsonl.bz2\n",
      " 5/88\n",
      "GDL-1953.jsonl.bz2\n",
      " 6/88\n",
      "GDL-1954.jsonl.bz2\n",
      " 7/88\n",
      "GDL-1955.jsonl.bz2\n",
      " 8/88\n",
      "GDL-1956.jsonl.bz2\n",
      " 9/88\n",
      "GDL-1957.jsonl.bz2\n",
      " 10/88\n",
      "GDL-1958.jsonl.bz2\n",
      " 11/88\n",
      "GDL-1959.jsonl.bz2\n",
      " 12/88\n",
      "GDL-1960.jsonl.bz2\n",
      " 13/88\n",
      "GDL-1961.jsonl.bz2\n",
      " 14/88\n",
      "GDL-1962.jsonl.bz2\n",
      " 15/88\n",
      "GDL-1963.jsonl.bz2\n",
      " 16/88\n",
      "GDL-1964.jsonl.bz2\n",
      " 17/88\n",
      "GDL-1965.jsonl.bz2\n",
      " 18/88\n",
      "GDL-1966.jsonl.bz2\n",
      " 19/88\n",
      "GDL-1967.jsonl.bz2\n",
      " 20/88\n",
      "GDL-1968.jsonl.bz2\n",
      " 21/88\n",
      "GDL-1969.jsonl.bz2\n",
      " 22/88\n",
      "GDL-1970.jsonl.bz2\n",
      " 23/88\n",
      "GDL-1971.jsonl.bz2\n",
      " 24/88\n",
      "GDL-1972.jsonl.bz2\n",
      " 25/88\n",
      "GDL-1973.jsonl.bz2\n",
      " 26/88\n",
      "GDL-1974.jsonl.bz2\n",
      " 27/88\n",
      "GDL-1975.jsonl.bz2\n",
      " 28/88\n",
      "GDL-1976.jsonl.bz2\n",
      " 29/88\n",
      "GDL-1977.jsonl.bz2\n",
      " 30/88\n",
      "GDL-1978.jsonl.bz2\n",
      " 31/88\n",
      "GDL-1979.jsonl.bz2\n",
      " 32/88\n",
      "GDL-1980.jsonl.bz2\n",
      " 33/88\n",
      "GDL-1981.jsonl.bz2\n",
      " 34/88\n",
      "GDL-1982.jsonl.bz2\n",
      " 35/88\n",
      "GDL-1983.jsonl.bz2\n",
      " 36/88\n",
      "GDL-1984.jsonl.bz2\n",
      " 37/88\n",
      "GDL-1985.jsonl.bz2\n",
      " 38/88\n",
      "GDL-1986.jsonl.bz2\n",
      " 39/88\n",
      "GDL-1987.jsonl.bz2\n",
      " 40/88\n",
      "GDL-1988.jsonl.bz2\n",
      " 41/88\n",
      "GDL-1989.jsonl.bz2\n",
      " 42/88\n",
      "GDL-1990.jsonl.bz2\n",
      " 43/88\n",
      "GDL-1991.jsonl.bz2\n",
      " 44/88\n",
      "JDG-1948.jsonl.bz2\n",
      " 45/88\n",
      "JDG-1949.jsonl.bz2\n",
      " 46/88\n",
      "JDG-1950.jsonl.bz2\n",
      " 47/88\n",
      "JDG-1951.jsonl.bz2\n",
      " 48/88\n",
      "JDG-1952.jsonl.bz2\n",
      " 49/88\n",
      "JDG-1953.jsonl.bz2\n",
      " 50/88\n",
      "JDG-1954.jsonl.bz2\n",
      " 51/88\n",
      "JDG-1955.jsonl.bz2\n",
      " 52/88\n",
      "JDG-1956.jsonl.bz2\n",
      " 53/88\n",
      "JDG-1957.jsonl.bz2\n",
      " 54/88\n",
      "JDG-1958.jsonl.bz2\n",
      " 55/88\n",
      "JDG-1959.jsonl.bz2\n",
      " 56/88\n",
      "JDG-1960.jsonl.bz2\n",
      " 57/88\n",
      "JDG-1961.jsonl.bz2\n",
      " 58/88\n",
      "JDG-1962.jsonl.bz2\n",
      " 59/88\n",
      "JDG-1963.jsonl.bz2\n",
      " 60/88\n",
      "JDG-1964.jsonl.bz2\n",
      " 61/88\n",
      "JDG-1965.jsonl.bz2\n",
      " 62/88\n",
      "JDG-1966.jsonl.bz2\n",
      " 63/88\n",
      "JDG-1967.jsonl.bz2\n",
      " 64/88\n",
      "JDG-1968.jsonl.bz2\n",
      " 65/88\n",
      "JDG-1969.jsonl.bz2\n",
      " 66/88\n",
      "JDG-1970.jsonl.bz2\n",
      " 67/88\n",
      "JDG-1971.jsonl.bz2\n",
      " 68/88\n",
      "JDG-1972.jsonl.bz2\n",
      " 69/88\n",
      "JDG-1973.jsonl.bz2\n",
      " 70/88\n",
      "JDG-1974.jsonl.bz2\n",
      " 71/88\n",
      "JDG-1975.jsonl.bz2\n",
      " 72/88\n",
      "JDG-1976.jsonl.bz2\n",
      " 73/88\n",
      "JDG-1977.jsonl.bz2\n",
      " 74/88\n",
      "JDG-1978.jsonl.bz2\n",
      " 75/88\n",
      "JDG-1979.jsonl.bz2\n",
      " 76/88\n",
      "JDG-1980.jsonl.bz2\n",
      " 77/88\n",
      "JDG-1981.jsonl.bz2\n",
      " 78/88\n",
      "JDG-1982.jsonl.bz2\n",
      " 79/88\n",
      "JDG-1983.jsonl.bz2\n",
      " 80/88\n",
      "JDG-1984.jsonl.bz2\n",
      " 81/88\n",
      "JDG-1985.jsonl.bz2\n",
      " 82/88\n",
      "JDG-1986.jsonl.bz2\n",
      " 83/88\n",
      "JDG-1987.jsonl.bz2\n",
      " 84/88\n",
      "JDG-1988.jsonl.bz2\n",
      " 85/88\n",
      "JDG-1989.jsonl.bz2\n",
      " 86/88\n",
      "JDG-1990.jsonl.bz2\n",
      " 87/88\n",
      "JDG-1991.jsonl.bz2\n",
      " 88/88\n"
     ]
    }
   ],
   "source": [
    "createOurCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_read = os.listdir(pathToBz2)\n",
    "files_to_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### y: year, m: month, d: day, deltap: the delta from dateEvent to max in days, deltan: the delta to dateEvent from min in days\n",
    "### dateEventstring: date of the event we want to look at.\n",
    "def csvtxtwriter(csvname, y, m, d, deltap, deltan, word):\n",
    "    nb =0\n",
    "    count =0\n",
    "    dateMax = datetime.timedelta(days = deltap)\n",
    "    dateMin = datetime.timedelta(days = deltan)\n",
    "    dateEventstring = str(y)+\"-\"+str(m) + \"-\"+str(d)\n",
    "    dateEvent = datetime.datetime.strptime(dateEventstring, '%Y-%m-%d')\n",
    "    pathCSV = \"csv/\"\n",
    "    text_articletxt = \"\"\n",
    "    returntxt = open(csvname[0:5] + \".txt\", \"w+\")\n",
    "    with open(pathCSV + csvname, 'w+', newline='') as csvFinal:\n",
    "        linewriter = csv.writer(csvFinal, delimiter = '*')\n",
    "        linewriter.writerow([\"date\", \"pp\", \"lenstring\", \"frequency\"])\n",
    "        for file in files_to_read:\n",
    "            nb +=1\n",
    "            #open the file \n",
    "            f = BZ2File(os.path.join(pathToBz2, file), 'r')\n",
    "            # get the list of articles it contains (= a json object on each line)\n",
    "            articles = list(read_jsonlines(f))\n",
    "            # load the first 100 articles as json and access their attributes\n",
    "\n",
    "            for a in articles:\n",
    "                # decode the json string into an object (dict)\n",
    "                json_article = json.loads(a)\n",
    "                datearticle = datetime.datetime.strptime(json_article[\"d\"], '%Y-%m-%d')\n",
    "                if ((datearticle - dateEvent < dateMax) and (datearticle - dateEvent > dateMin) and (word in json_article[\"ft\"].lower())) :\n",
    "                    text_articletxt = text_articletxt + \" \\n**** *id:\" + str(count) + \" *from:\" + file + \"  \\n \" + json_article[\"ft\"]\n",
    "\n",
    "                    linewriter.writerow([str(json_article[\"d\"][:7]), json_article['pp'][0], len(json_article['ft']), int(1)]) ###if we want groupbyday: remove [:7]\n",
    "                    count += 1\n",
    "    returntxt.write(text_articletxt)\n",
    "    returntxt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apartheidCSV():\n",
    "    with open(\"csv/apartheid.csv\", 'w+', newline='') as csvFinal:\n",
    "        linewriter = csv.writer(csvFinal, delimiter = '*')\n",
    "        linewriter.writerow([\"date\", \"pp\", \"lenstring\", \"frequency\"])\n",
    "        for file in files_to_read:\n",
    "            f = BZ2File(os.path.join(pathToBz2, file), 'r')\n",
    "            articles = list(read_jsonlines(f))\n",
    "            for a in articles:\n",
    "                json_article = json.loads(a)\n",
    "                linewriter.writerow([str(json_article['d'][:4]), json_article['pp'][0], len(json_article['ft']), int(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datey = [1948, 1960, 1976, 1983, 1986, 1990, 1990, 1962, 1949]\n",
    "datem = [6, 3, 6, 5, 6, 3, 2, 8, 6]\n",
    "dated = [15, 21, 16, 20, 12, 15, 11, 15, 29]\n",
    "title = [\"d√©but de l'Apartheid\", \"Massacre de Sharpeville\", \"√âmeutes de Soweto\", \"Attentat de Church Street\", \"√©tat d'urgence\", \"l√©galisation des partis politiques\", \"lib√©ration de Mandela\", \"Condamnation de Mandela\", \"test1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupbycsvme(csvname):\n",
    "    a = pd.read_csv(\"csv/\"+csvname, delimiter='*')\n",
    "    futurG = a.groupby(['date']).sum().sort_values(by='date').reset_index()\n",
    "    with open(\"csvGrouped/\" + csvname, 'w+', newline='') as csvFinal:\n",
    "        linewriter = csv.writer(csvFinal, delimiter = '*')\n",
    "        linewriter.writerow([\"date\", \"pp\", \"lenstring\", \"frequency\"])\n",
    "        for i in range(0,len(futurG)):\n",
    "            linewriter.writerow([futurG['date'].iloc[i], futurG['pp'].iloc[i], futurG['lenstring'].iloc[i], futurG['frequency'].iloc[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apartheidCSV()\n",
    "for d in range(0, len(datey)-1):\n",
    "    print(str(d+1) + \"/\"+str(len(datey)-1))\n",
    "    name = str(datey[d]) +\"_\" + str(datem[d]) + \".csv\"\n",
    "    csvtxtwriter(name, datey[d], datem[d], dated[d], 388, -388)\n",
    "    groupbycsvme(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = str(datey[1]) +\"_\" + str(datem[1]) + \".csv\"\n",
    "\n",
    "csvtxtwriter(name, datey[1], datem[1], dated[1], 388, -388, \"sharpeville\")\n",
    "groupbycsvme(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
